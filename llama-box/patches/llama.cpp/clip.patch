diff --git a/tools/mtmd/clip-impl.h b/tools/mtmd/clip-impl.h
index 62c936ed..e393462f 100644
--- a/tools/mtmd/clip-impl.h
+++ b/tools/mtmd/clip-impl.h
@@ -226,6 +226,7 @@ static void clip_log_internal(enum ggml_log_level level, const char * format, ..
     va_end(args);
 }
 
+#ifndef LOG_TMPL
 #define LOG_TMPL(level, ...) \
     do { \
         if ((level) >= g_logger_state.verbosity_thold) { \
@@ -237,6 +238,7 @@ static void clip_log_internal(enum ggml_log_level level, const char * format, ..
 #define LOG_ERR(...) LOG_TMPL(GGML_LOG_LEVEL_ERROR, __VA_ARGS__)
 #define LOG_DBG(...) LOG_TMPL(GGML_LOG_LEVEL_DEBUG, __VA_ARGS__)
 #define LOG_CNT(...) LOG_TMPL(GGML_LOG_LEVEL_CONT,  __VA_ARGS__)
+#endif
 
 //
 // cpp wrappers
@@ -292,6 +294,7 @@ struct clip_image_f32_batch {
 // common utils
 //
 
+#ifndef DIRECTORY_SEPARATOR
 static std::string string_format(const char * fmt, ...) {
     va_list ap;
     va_list ap2;
@@ -323,6 +326,7 @@ static void string_replace_all(std::string & s, const std::string & search, cons
     builder.append(s, last_pos, std::string::npos);
     s = std::move(builder);
 }
+#endif
 
 // split string by a `std::string delim` instead of `char delim`
 static std::vector<std::string> string_split_str(std::string s, const std::string & delimiter) {
diff --git a/tools/mtmd/clip.cpp b/tools/mtmd/clip.cpp
index 30283d6f..d362cff0 100644
--- a/tools/mtmd/clip.cpp
+++ b/tools/mtmd/clip.cpp
@@ -30,6 +30,11 @@
 
 struct clip_logger_state g_logger_state = {GGML_LOG_LEVEL_CONT, clip_log_callback_default, NULL};
 
+void clip_log_set(ggml_log_callback log_callback, void * user_data) {
+    g_logger_state.log_callback = log_callback ? log_callback : clip_log_callback_default;
+    g_logger_state.log_callback_user_data = user_data;
+}
+
 enum ffn_op_type {
     FFN_GELU,
     FFN_GELU_ERF,
@@ -164,7 +169,7 @@ enum patch_merge_type {
 
 struct clip_hparams {
     int32_t image_size;
-    int32_t patch_size;
+    int32_t patch_size = 1;
     int32_t n_embd;
     int32_t n_ff;
     int32_t projection_dim;
@@ -2061,7 +2066,7 @@ struct clip_model_loader {
         }
     }
 
-    void load_hparams(clip_model & model, clip_modality modality) {
+    void load_hparams(clip_model & model, clip_modality modality, int32_t max_image_size = 0) {
         auto & hparams = model.hparams;
         std::string log_ffn_op; // for logging
 
@@ -2209,8 +2214,9 @@ struct clip_model_loader {
                     } break;
                 case PROJECTOR_TYPE_PIXTRAL:
                     {
+                        hparams.image_size = max_image_size <= 0 ? hparams.image_size : max_image_size;
                         hparams.rope_theta = 10000.0f;
-                        hparams.warmup_image_size = hparams.patch_size * 8;
+                        hparams.warmup_image_size = max_image_size <= 0 ? hparams.patch_size * 8 : max_image_size;
                         get_u32(KEY_SPATIAL_MERGE_SIZE, hparams.spatial_merge_size, false);
                     } break;
                 case PROJECTOR_TYPE_GEMMA3:
@@ -2227,8 +2233,8 @@ struct clip_model_loader {
                         // ref: https://huggingface.co/Qwen/Qwen2-VL-7B-Instruct/blob/main/preprocessor_config.json
                         // however, the model use unreasonable memory past 1024 size, we force it to 1024 otherwise it's unusable
                         // ref: https://huggingface.co/Qwen/Qwen2-VL-2B-Instruct/discussions/10
-                        hparams.image_size = 1024;
-                        hparams.warmup_image_size = hparams.patch_size * 8;
+                        hparams.image_size = max_image_size <= 0 ? 1024 : max_image_size;
+                        hparams.warmup_image_size = max_image_size <= 0 ? hparams.patch_size * 8 : max_image_size;
                     } break;
                 case PROJECTOR_TYPE_QWEN25VL:
                     {
@@ -2236,8 +2242,8 @@ struct clip_model_loader {
                         // https://huggingface.co/Qwen/Qwen2.5-VL-7B-Instruct/blob/main/preprocessor_config.json
                         // however, the model use unreasonable memory past 1024 size, we force it to 1024 otherwise it's unusable
                         // ref: https://huggingface.co/Qwen/Qwen2-VL-2B-Instruct/discussions/10
-                        hparams.image_size = 1024;
-                        hparams.warmup_image_size = hparams.patch_size * 8;
+                        hparams.image_size = max_image_size <= 0 ? 1024 : max_image_size;
+                        hparams.warmup_image_size = max_image_size <= 0 ? hparams.patch_size * 8 : max_image_size;
                         get_u32(KEY_WIN_ATTN_PATTERN, hparams.n_wa_pattern);
                     } break;
                 case PROJECTOR_TYPE_LLAMA4:
@@ -2293,6 +2299,19 @@ struct clip_model_loader {
         std::map<std::string, size_t> tensor_offset;
         std::vector<ggml_tensor *> tensors_to_load;
 
+#if (defined GGML_USE_CANN) || (defined GGML_USE_VULKAN)
+        if ((model.proj_type == PROJECTOR_TYPE_QWEN2VL || model.proj_type == PROJECTOR_TYPE_QWEN25VL || model.proj_type == PROJECTOR_TYPE_QWEN2A) && !ggml_backend_is_cpu(ctx_clip.backend)) {
+            LOG_WRN("%s", "Qwen2VL/Qwen25VL merger is not supported on current backend, fallback to CPU backend\n");
+            ggml_backend_free(ctx_clip.backend);
+            ctx_clip.backend = ctx_clip.backend_cpu;
+            ctx_clip.backend_ptrs.erase(ctx_clip.backend_ptrs.begin());
+            ctx_clip.backend_buft.erase(ctx_clip.backend_buft.begin());
+            ctx_clip.sched.reset(
+                ggml_backend_sched_new(ctx_clip.backend_ptrs.data(), ctx_clip.backend_buft.data(), ctx_clip.backend_ptrs.size(), 8192, false, true)
+            );
+        }
+#endif
+
         // TODO @ngxson : support both audio and video in the future
         const char * prefix = model.modality == CLIP_MODALITY_AUDIO ? "a" : "v";
 
@@ -2705,7 +2724,7 @@ struct clip_init_result clip_init(const char * fname, struct clip_context_params
 
         if (loader.has_vision) {
             ctx_vision = new clip_ctx(ctx_params);
-            loader.load_hparams(ctx_vision->model, CLIP_MODALITY_VISION);
+            loader.load_hparams(ctx_vision->model, CLIP_MODALITY_VISION, ctx_params.max_image_size);
             loader.load_tensors(*ctx_vision);
             loader.alloc_compute_meta(*ctx_vision);
         }
@@ -2820,6 +2839,11 @@ static void normalize_image_u8_to_f32(const clip_image_u8 & src, clip_image_f32
 struct image_manipulation {
     // Bilinear resize function
     static void bilinear_resize(const clip_image_u8& src, clip_image_u8& dst, int target_width, int target_height) {
+        if (src.nx == target_width && src.ny == target_height) {
+            dst = src; // no resize needed
+            return;
+        }
+
         dst.nx = target_width;
         dst.ny = target_height;
         dst.buf.resize(3 * target_width * target_height);
@@ -2856,6 +2880,11 @@ struct image_manipulation {
     // Bicubic resize function
     // part of image will be cropped if the aspect ratio is different
     static bool bicubic_resize(const clip_image_u8 & img, clip_image_u8 & dst, int target_width, int target_height) {
+        if (img.nx == target_width && img.ny == target_height) {
+            dst = img; // no resize needed
+            return true;
+        }
+
         const int nx = img.nx;
         const int ny = img.ny;
 
@@ -2991,6 +3020,9 @@ struct image_manipulation {
         if (inp_size.width <= 0 || inp_size.height <= 0 || align_size <= 0 || max_dimension <= 0) {
             return {0, 0};
         }
+        if (inp_size.width <= max_dimension && inp_size.height <= max_dimension) {
+            return {CLIP_ALIGN(inp_size.width, align_size), CLIP_ALIGN(inp_size.height, align_size)};
+        }
 
         float scale = std::min(1.0f, std::min(static_cast<float>(max_dimension) / inp_size.width,
                                               static_cast<float>(max_dimension) / inp_size.height));
@@ -3340,7 +3372,7 @@ bool clip_image_preprocess(struct clip_ctx * ctx, const clip_image_u8 * img, str
         clip_image_u8 resized;
         auto patch_size = params.patch_size * 2;
         auto new_size = image_manipulation::calc_size_preserved_ratio(original_size, patch_size, params.image_size);
-        image_manipulation::bicubic_resize(*img, resized, new_size.width, new_size.height);
+        image_manipulation::bilinear_resize(*img, resized, new_size.width, new_size.height);
 
         clip_image_f32_ptr img_f32(clip_image_f32_init());
         // clip_image_f32_ptr res(clip_image_f32_init());
@@ -4111,6 +4143,30 @@ bool clip_is_gemma3(const struct clip_ctx * ctx) {
     return ctx->proj_type() == PROJECTOR_TYPE_GEMMA3;
 }
 
+bool clip_is_smolvlm(const struct clip_ctx * ctx) {
+    return ctx->proj_type() == PROJECTOR_TYPE_IDEFICS3;
+}
+
+bool clip_is_pixtral(const struct clip_ctx * ctx) {
+    return ctx->proj_type() == PROJECTOR_TYPE_PIXTRAL;
+}
+
+bool clip_is_internvl(const struct clip_ctx * ctx) {
+    return ctx->proj_type() == PROJECTOR_TYPE_INTERNVL;
+}
+
+bool clip_is_llama4(const struct clip_ctx * ctx) {
+    return ctx->proj_type() == PROJECTOR_TYPE_LLAMA4;
+}
+
+bool clip_is_ultravox(const struct clip_ctx * ctx) {
+    return ctx->proj_type() == PROJECTOR_TYPE_ULTRAVOX;
+}
+
+bool clip_is_qwen2a(const struct clip_ctx * ctx) {
+    return ctx->proj_type() == PROJECTOR_TYPE_QWEN2A;
+}
+
 bool clip_has_vision_encoder(const struct clip_ctx * ctx) {
     return ctx->model.modality == CLIP_MODALITY_VISION;
 }
diff --git a/tools/mtmd/clip.h b/tools/mtmd/clip.h
index 08f3efb7..d90921f6 100644
--- a/tools/mtmd/clip.h
+++ b/tools/mtmd/clip.h
@@ -6,6 +6,20 @@
 
 // !!! Internal header, to be used by mtmd only !!!
 
+#ifdef LLAMA_SHARED
+#    if defined(_WIN32) && !defined(__MINGW32__)
+#        ifdef LLAMA_BUILD
+#            define CLIP_API __declspec(dllexport)
+#        else
+#            define CLIP_API __declspec(dllimport)
+#        endif
+#    else
+#        define CLIP_API __attribute__ ((visibility ("default")))
+#    endif
+#else
+#    define CLIP_API
+#endif
+
 struct clip_ctx;
 
 struct clip_image_size {
@@ -25,87 +39,96 @@ enum clip_modality {
 struct clip_context_params {
     bool use_gpu;
     enum ggml_log_level verbosity;
+    int max_image_size = 0;
 };
 
+CLIP_API void clip_log_set(ggml_log_callback log_callback, void * user_data);
+
 struct clip_init_result {
     struct clip_ctx * ctx_v; // vision context
     struct clip_ctx * ctx_a; // audio context
 };
 
-struct clip_init_result clip_init(const char * fname, struct clip_context_params ctx_params);
+CLIP_API struct clip_init_result clip_init(const char * fname, struct clip_context_params ctx_params);
 
-void clip_free(struct clip_ctx * ctx);
+CLIP_API void clip_free(struct clip_ctx * ctx);
 
-size_t clip_embd_nbytes(const struct clip_ctx * ctx);
-size_t clip_embd_nbytes_by_img(const struct clip_ctx * ctx, int img_w, int img_h);
+CLIP_API size_t clip_embd_nbytes(const struct clip_ctx * ctx);
+CLIP_API size_t clip_embd_nbytes_by_img(const struct clip_ctx * ctx, int img_w, int img_h);
 
-int32_t clip_get_image_size (const struct clip_ctx * ctx);
-int32_t clip_get_patch_size (const struct clip_ctx * ctx);
-int32_t clip_get_hidden_size(const struct clip_ctx * ctx);
+CLIP_API int32_t clip_get_image_size (const struct clip_ctx * ctx);
+CLIP_API int32_t clip_get_patch_size (const struct clip_ctx * ctx);
+CLIP_API int32_t clip_get_hidden_size(const struct clip_ctx * ctx);
 
 // TODO: should be enum, not string
-const char * clip_patch_merge_type(const struct clip_ctx * ctx);
+CLIP_API const char * clip_patch_merge_type(const struct clip_ctx * ctx);
 
-int clip_n_output_tokens(const struct clip_ctx * ctx, struct clip_image_f32 * img);
+CLIP_API int clip_n_output_tokens(const struct clip_ctx * ctx, struct clip_image_f32 * img);
 
 // for M-RoPE, this will be the number of token positions in X and Y directions
 // for other models, X will be the total number of tokens and Y will be 1
-int clip_n_output_tokens_x(const struct clip_ctx * ctx, struct clip_image_f32 * img);
-int clip_n_output_tokens_y(const struct clip_ctx * ctx, struct clip_image_f32 * img);
+CLIP_API int clip_n_output_tokens_x(const struct clip_ctx * ctx, struct clip_image_f32 * img);
+CLIP_API int clip_n_output_tokens_y(const struct clip_ctx * ctx, struct clip_image_f32 * img);
 
 // this should be equal to the embedding dimension of the text model
-int clip_n_mmproj_embd(const struct clip_ctx * ctx);
+CLIP_API int clip_n_mmproj_embd(const struct clip_ctx * ctx);
 
-struct clip_image_size      * clip_image_size_init(void);
-struct clip_image_u8        * clip_image_u8_init (void);
-struct clip_image_f32       * clip_image_f32_init(void);
-struct clip_image_f32_batch * clip_image_f32_batch_init(void); // only used by libllava
+CLIP_API struct clip_image_size      * clip_image_size_init(void);
+CLIP_API struct clip_image_u8        * clip_image_u8_init (void);
+CLIP_API struct clip_image_f32       * clip_image_f32_init(void);
+CLIP_API struct clip_image_f32_batch * clip_image_f32_batch_init(void); // only used by libllava
 
 // nx, ny are the output image dimensions
-unsigned char * clip_image_u8_get_data(struct clip_image_u8 * img, uint32_t * nx, uint32_t * ny);
+CLIP_API unsigned char * clip_image_u8_get_data(struct clip_image_u8 * img, uint32_t * nx, uint32_t * ny);
 
-void clip_image_size_free (struct clip_image_size * img_size);
-void clip_image_u8_free (struct clip_image_u8  * img);
-void clip_image_f32_free(struct clip_image_f32 * img);
-void clip_image_u8_batch_free (struct clip_image_u8_batch  * batch);
-void clip_image_f32_batch_free(struct clip_image_f32_batch * batch);
+CLIP_API void clip_image_size_free (struct clip_image_size * img_size);
+CLIP_API void clip_image_u8_free (struct clip_image_u8  * img);
+CLIP_API void clip_image_f32_free(struct clip_image_f32 * img);
+CLIP_API void clip_image_u8_batch_free (struct clip_image_u8_batch  * batch);
+CLIP_API void clip_image_f32_batch_free(struct clip_image_f32_batch * batch);
 
 // use for accessing underlay data of clip_image_f32_batch
-size_t clip_image_f32_batch_n_images(const struct clip_image_f32_batch * batch); // equivalent to batch->size()
-size_t clip_image_f32_batch_nx(const struct clip_image_f32_batch * batch, int idx); // equivalent to batch[idx]->nx
-size_t clip_image_f32_batch_ny(const struct clip_image_f32_batch * batch, int idx); // equivalent to batch[idx]->ny
-struct clip_image_f32 * clip_image_f32_get_img(const struct clip_image_f32_batch * batch, int idx); // equivalent to batch[idx]->data
+CLIP_API size_t clip_image_f32_batch_n_images(const struct clip_image_f32_batch * batch); // equivalent to batch->size()
+CLIP_API size_t clip_image_f32_batch_nx(const struct clip_image_f32_batch * batch, int idx); // equivalent to batch[idx]->nx
+CLIP_API size_t clip_image_f32_batch_ny(const struct clip_image_f32_batch * batch, int idx); // equivalent to batch[idx]->ny
+CLIP_API struct clip_image_f32 * clip_image_f32_get_img(const struct clip_image_f32_batch * batch, int idx); // equivalent to batch[idx]->data
 
 /**
  * Build image from pixels decoded by other libraries instead of stb_image.h for better performance.
  * The memory layout is RGBRGBRGB..., input buffer length must be 3*nx*ny bytes
  */
-void clip_build_img_from_pixels(const unsigned char * rgb_pixels, int nx, int ny, struct clip_image_u8 * img);
+CLIP_API void clip_build_img_from_pixels(const unsigned char * rgb_pixels, int nx, int ny, struct clip_image_u8 * img);
 
-bool clip_image_load_from_file(const char * fname, struct clip_image_u8 * img);
+CLIP_API bool clip_image_load_from_file(const char * fname, struct clip_image_u8 * img);
 
 /** interpret bytes as an image file with length bytes_length, and use the result to populate img */
-bool clip_image_load_from_bytes(const unsigned char * bytes, size_t bytes_length, struct clip_image_u8 * img);
+CLIP_API bool clip_image_load_from_bytes(const unsigned char * bytes, size_t bytes_length, struct clip_image_u8 * img);
 
 /** preprocess img and store the result in res_imgs, pad_to_square may be overridden to false depending on model configuration */
-bool clip_image_preprocess(struct clip_ctx * ctx, const struct clip_image_u8 * img, struct clip_image_f32_batch * res_imgs );
+CLIP_API bool clip_image_preprocess(struct clip_ctx * ctx, const struct clip_image_u8 * img, struct clip_image_f32_batch * res_imgs );
 
-struct ggml_tensor * clip_get_newline_tensor(const struct clip_ctx * ctx);
+CLIP_API struct ggml_tensor * clip_get_newline_tensor(const struct clip_ctx * ctx);
 
-bool clip_image_encode      (struct clip_ctx * ctx, int n_threads, struct clip_image_f32 * img, float * vec);
-bool clip_image_batch_encode(struct clip_ctx * ctx, int n_threads, const struct clip_image_f32_batch * imgs, float * vec);
+CLIP_API bool clip_image_encode      (struct clip_ctx * ctx, int n_threads, struct clip_image_f32 * img, float * vec);
+CLIP_API bool clip_image_batch_encode(struct clip_ctx * ctx, int n_threads, const struct clip_image_f32_batch * imgs, float * vec);
 
-int clip_is_minicpmv(const struct clip_ctx * ctx);
-bool clip_is_glm(const struct clip_ctx * ctx);
-bool clip_is_qwen2vl(const struct clip_ctx * ctx);
-bool clip_is_llava(const struct clip_ctx * ctx);
-bool clip_is_gemma3(const struct clip_ctx * ctx);
+CLIP_API int clip_is_minicpmv(const struct clip_ctx * ctx);
+CLIP_API bool clip_is_glm(const struct clip_ctx * ctx);
+CLIP_API bool clip_is_qwen2vl(const struct clip_ctx * ctx);
+CLIP_API bool clip_is_llava(const struct clip_ctx * ctx);
+CLIP_API bool clip_is_gemma3(const struct clip_ctx * ctx);
+CLIP_API bool clip_is_smolvlm(const struct clip_ctx * ctx);
+CLIP_API bool clip_is_pixtral(const struct clip_ctx * ctx);
+CLIP_API bool clip_is_internvl(const struct clip_ctx * ctx);
+CLIP_API bool clip_is_llama4(const struct clip_ctx * ctx);
+CLIP_API bool clip_is_ultravox(const struct clip_ctx * ctx);
+CLIP_API bool clip_is_qwen2a(const struct clip_ctx * ctx);
 
-bool clip_encode_float_image (struct clip_ctx * ctx, int n_threads, float * img, int h, int w, float * vec);
+CLIP_API bool clip_encode_float_image (struct clip_ctx * ctx, int n_threads, float * img, int h, int w, float * vec);
 
 // use by audio input
-void clip_image_f32_batch_add_mel(struct clip_image_f32_batch * batch, int n_mel, int n_frames, float * mel);
+CLIP_API void clip_image_f32_batch_add_mel(struct clip_image_f32_batch * batch, int n_mel, int n_frames, float * mel);
 
-bool clip_has_vision_encoder(const struct clip_ctx * ctx);
-bool clip_has_audio_encoder(const struct clip_ctx * ctx);
-bool clip_has_whisper_encoder(const struct clip_ctx * ctx);
+CLIP_API bool clip_has_vision_encoder(const struct clip_ctx * ctx);
+CLIP_API bool clip_has_audio_encoder(const struct clip_ctx * ctx);
+CLIP_API bool clip_has_whisper_encoder(const struct clip_ctx * ctx);
diff --git a/tools/mtmd/mtmd-audio.h b/tools/mtmd/mtmd-audio.h
index b7b940af..91d31d16 100644
--- a/tools/mtmd/mtmd-audio.h
+++ b/tools/mtmd/mtmd-audio.h
@@ -15,6 +15,20 @@
 
 #define COMMON_SAMPLE_RATE 16000
 
+#ifdef LLAMA_SHARED
+#    if defined(_WIN32) && !defined(__MINGW32__)
+#        ifdef LLAMA_BUILD
+#            define MTMD_AUDIO_API __declspec(dllexport)
+#        else
+#            define MTMD_AUDIO_API __declspec(dllimport)
+#        endif
+#    else
+#        define MTMD_AUDIO_API __attribute__ ((visibility ("default")))
+#    endif
+#else
+#    define MTMD_AUDIO_API
+#endif
+
 namespace whisper_preprocessor {
 
 struct whisper_mel {
@@ -32,7 +46,7 @@ struct whisper_filters {
     std::vector<float> data;
 };
 
-bool preprocess_audio(
+MTMD_AUDIO_API bool preprocess_audio(
         const float * samples,
         size_t n_samples,
         const whisper_filters & filters,
@@ -42,6 +56,6 @@ bool preprocess_audio(
 
 namespace whisper_precalc_filters {
 
-whisper_preprocessor::whisper_filters get_128_bins();
+MTMD_AUDIO_API whisper_preprocessor::whisper_filters get_128_bins();
 
 } // namespace whisper_precalc_filters
diff --git a/tools/mtmd/mtmd-helper.cpp b/tools/mtmd/mtmd-helper.cpp
index 686f42f3..eead1f8e 100644
--- a/tools/mtmd/mtmd-helper.cpp
+++ b/tools/mtmd/mtmd-helper.cpp
@@ -458,3 +458,7 @@ mtmd_bitmap * mtmd_helper_bitmap_init_from_file(mtmd_context * ctx, const char *
 
     return mtmd_helper_bitmap_init_from_buf(ctx, buf.data(), buf.size());
 }
+
+bool decode_audio_from_buf(const unsigned char * buf_in, size_t len, int target_sampler_rate, std::vector<float> & pcmf32_mono) {
+    return audio_helpers::decode_audio_from_buf(buf_in, len, target_sampler_rate, pcmf32_mono);
+}
\ No newline at end of file
diff --git a/tools/mtmd/mtmd-helper.h b/tools/mtmd/mtmd-helper.h
index 5c0edc69..f474b0c9 100644
--- a/tools/mtmd/mtmd-helper.h
+++ b/tools/mtmd/mtmd-helper.h
@@ -80,6 +80,8 @@ MTMD_API int32_t mtmd_helper_decode_image_chunk(mtmd_context * ctx,
                                                 int32_t n_batch,
                                                 llama_pos * new_n_past);
 
+MTMD_API bool decode_audio_from_buf(const unsigned char * buf_in, size_t len, int target_sampler_rate, std::vector<float> & pcmf32_mono);
+
 #ifdef __cplusplus
 } // extern "C"
 #endif
