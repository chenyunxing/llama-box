diff --git a/tools/llava/clip-impl.h b/tools/llava/clip-impl.h
index b78d930b..6991796b 100644
--- a/tools/llava/clip-impl.h
+++ b/tools/llava/clip-impl.h
@@ -193,17 +193,7 @@ static void clip_log_internal(enum ggml_log_level level, const char * format, ..
     va_end(args);
 }
 
-#define LOG_TMPL(level, ...) \
-    do { \
-        if ((level) >= g_logger_state.verbosity_thold) { \
-            clip_log_internal((level), __VA_ARGS__); \
-        } \
-    } while (0)
-#define LOG_INF(...) LOG_TMPL(GGML_LOG_LEVEL_INFO,  __VA_ARGS__)
-#define LOG_WRN(...) LOG_TMPL(GGML_LOG_LEVEL_WARN,  __VA_ARGS__)
-#define LOG_ERR(...) LOG_TMPL(GGML_LOG_LEVEL_ERROR, __VA_ARGS__)
-#define LOG_DBG(...) LOG_TMPL(GGML_LOG_LEVEL_DEBUG, __VA_ARGS__)
-#define LOG_CNT(...) LOG_TMPL(GGML_LOG_LEVEL_CONT,  __VA_ARGS__)
+#include "common/log.h"
 
 //
 // cpp wrappers
@@ -239,37 +229,7 @@ struct clip_image_f32_batch {
 // common utils
 //
 
-static std::string string_format(const char * fmt, ...) {
-    va_list ap;
-    va_list ap2;
-    va_start(ap, fmt);
-    va_copy(ap2, ap);
-    int size = vsnprintf(NULL, 0, fmt, ap);
-    GGML_ASSERT(size >= 0 && size < INT_MAX); // NOLINT
-    std::vector<char> buf(size + 1);
-    int size2 = vsnprintf(buf.data(), size + 1, fmt, ap2);
-    GGML_ASSERT(size2 == size);
-    va_end(ap2);
-    va_end(ap);
-    return std::string(buf.data(), buf.size());
-}
-
-static void string_replace_all(std::string & s, const std::string & search, const std::string & replace) {
-    if (search.empty()) {
-        return;
-    }
-    std::string builder;
-    builder.reserve(s.length());
-    size_t pos = 0;
-    size_t last_pos = 0;
-    while ((pos = s.find(search, last_pos)) != std::string::npos) {
-        builder.append(s, last_pos, pos - last_pos);
-        builder.append(replace);
-        last_pos = pos + search.length();
-    }
-    builder.append(s, last_pos, std::string::npos);
-    s = std::move(builder);
-}
+#include "common/common.h"
 
 // split string by a `std::string delim` instead of `char delim`
 static std::vector<std::string> string_split_str(std::string s, const std::string & delimiter) {
diff --git a/tools/llava/clip.cpp b/tools/llava/clip.cpp
index 3b60a526..90b39b85 100644
--- a/tools/llava/clip.cpp
+++ b/tools/llava/clip.cpp
@@ -348,11 +348,14 @@ struct clip_ctx {
 
     clip_image_size load_image_size;
 
+    int max_image_size = 0;
+
     clip_ctx(clip_context_params & ctx_params) {
         backend_cpu = ggml_backend_init_by_type(GGML_BACKEND_DEVICE_TYPE_CPU, nullptr);
         backend     = ctx_params.use_gpu
                         ? ggml_backend_init_by_type(GGML_BACKEND_DEVICE_TYPE_GPU, nullptr)
                         : nullptr;
+        max_image_size = ctx_params.max_image_size;
 
         if (backend) {
             LOG_INF("%s: CLIP using %s backend\n", __func__, ggml_backend_name(backend));
@@ -1687,6 +1690,18 @@ struct clip_model_loader {
             if (ctx_clip.proj_type == PROJECTOR_TYPE_UNKNOWN) {
                 throw std::runtime_error(string_format("%s: unknown projector type: %s\n", __func__, proj_type.c_str()));
             }
+#if (!defined GGML_USE_CUDA) && (!defined GGML_USE_METAL)
+            if ((ctx_clip.proj_type == PROJECTOR_TYPE_QWEN2VL || ctx_clip.proj_type == PROJECTOR_TYPE_QWEN25VL) && !ggml_backend_is_cpu(ctx_clip.backend)) {
+                LOG_WRN("%s: Qwen2VL/Qwen25VL merger is not supported on current backend, fallback to CPU backend\n", __func__);
+                ggml_backend_free(ctx_clip.backend);
+                ctx_clip.backend = ctx_clip.backend_cpu;
+                ctx_clip.backend_ptrs.erase(ctx_clip.backend_ptrs.begin());
+                ctx_clip.backend_buft.erase(ctx_clip.backend_buft.begin());
+                ctx_clip.sched.reset(
+                    ggml_backend_sched_new(ctx_clip.backend_ptrs.data(), ctx_clip.backend_buft.data(), ctx_clip.backend_ptrs.size(), 8192, false)
+                );
+            }
+#endif
         }
 
         // other hparams
@@ -1786,6 +1801,14 @@ struct clip_model_loader {
                         hparams.rope_theta = 10000.0f;
                         get_u32(KEY_SPATIAL_MERGE_SIZE, hparams.spatial_merge_size, false);
                     } break;
+                case PROJECTOR_TYPE_GEMMA3:
+                    {
+                        // default value (used by all model sizes in gemma 3 family)
+                        // number of patches for each **side** is reduced by a factor of 4
+                        hparams.proj_scale_factor = 4;
+                        // test model (tinygemma3) has a different value, we optionally read it
+                        get_u32(KEY_PROJ_SCALE_FACTOR, hparams.proj_scale_factor, false);
+                    } break;
                 case PROJECTOR_TYPE_QWEN25VL:
                     {
                         get_u32(KEY_WIN_ATTN_PATTERN, hparams.n_wa_pattern);
@@ -2069,6 +2092,11 @@ struct clip_model_loader {
         clip_image_size image_size;
         image_size.width  = ctx_clip.vision_model.hparams.image_size;
         image_size.height = ctx_clip.vision_model.hparams.image_size;
+        if (ctx_clip.max_image_size > 0 &&
+            (ctx_clip.proj_type == PROJECTOR_TYPE_QWEN2VL || ctx_clip.proj_type == PROJECTOR_TYPE_QWEN25VL)) {
+            image_size.width  = ctx_clip.max_image_size;
+            image_size.height = ctx_clip.max_image_size;
+        }
         img->nx = image_size.width;
         img->ny = image_size.height;
         img->buf.resize(image_size.width * image_size.height * 3);
@@ -2615,7 +2643,7 @@ struct llava_uhd {
 
         // resize to overview size
         clip_image_u8_ptr resized_img(clip_image_u8_init());
-        image_manipulation::bicubic_resize(*img, *resized_img, inst.overview_size.width, inst.overview_size.height);
+        image_manipulation::resize_and_pad_image(*img, *resized_img, {inst.overview_size.width, inst.overview_size.height});
         output.push_back(std::move(resized_img));
         if (inst.slices.empty()) {
             // no slices, just return the resized image
@@ -2768,6 +2796,11 @@ int clip_uhd_num_image_embeds_col(struct clip_ctx * ctx_clip) {
     return inst.grid_size.width;
 }
 
+int clip_uhd_num_image_embeds_col2(struct clip_ctx *ctx_clip, struct clip_image_size *load_image_size) {
+    const auto inst = llava_uhd::get_slice_instructions(ctx_clip, *load_image_size);
+    return inst.grid_size.width;
+}
+
 // returns the normalized float tensor for llava-1.5, for spatial_unpad with anyres processing for llava-1.6 it returns the normalized image patch tensors as a vector
 // res_imgs memory is being allocated here, previous allocations will be freed if found
 bool clip_image_preprocess(struct clip_ctx * ctx, const clip_image_u8 * img, struct clip_image_f32_batch * res_imgs) {
@@ -2979,11 +3012,13 @@ int clip_n_output_tokens(const struct clip_ctx * ctx, struct clip_image_f32 * im
         int y_patch = img->ny / patch_size + (int)(img->ny % patch_size > 0);
         n_patches = x_patch * y_patch;
     } else if (ctx->proj_type == PROJECTOR_TYPE_GEMMA3) {
-        n_patches = 256;
+        int n_per_side = params.image_size / params.patch_size;
+        int n_per_side_2d_pool = n_per_side / (params.proj_scale_factor == 0 ? 1 : params.proj_scale_factor);
+        n_patches = n_per_side_2d_pool * n_per_side_2d_pool;
     } else if (ctx->proj_type == PROJECTOR_TYPE_IDEFICS3) {
-        n_patches /= ctx->vision_model.hparams.proj_scale_factor;
+        n_patches /= (params.proj_scale_factor * params.proj_scale_factor);
     } else if (ctx->proj_type == PROJECTOR_TYPE_PIXTRAL) {
-        int n_merge = ctx->vision_model.hparams.spatial_merge_size;
+        int n_merge = params.spatial_merge_size;
         int n_patches_x = img->nx / params.patch_size / (n_merge > 0 ? n_merge : 1);
         int n_patches_y = img->ny / params.patch_size / (n_merge > 0 ? n_merge : 1);
         n_patches = n_patches_y*n_patches_x + n_patches_y - 1; // + one [IMG_BREAK] per row, except the last row
@@ -3591,6 +3626,14 @@ bool clip_is_gemma3(const struct clip_ctx * ctx) {
     return ctx->proj_type == PROJECTOR_TYPE_GEMMA3;
 }
 
+bool clip_is_smolvlm(const struct clip_ctx * ctx) {
+    return ctx->proj_type == PROJECTOR_TYPE_IDEFICS3;
+}
+
+bool clip_is_pixtral(const struct clip_ctx * ctx) {
+    return ctx->proj_type == PROJECTOR_TYPE_PIXTRAL;
+}
+
 bool clip_encode_float_image (struct clip_ctx * ctx, int n_threads, float * img, int h, int w, float * vec) {
     clip_image_f32 clip_img;
     clip_img.buf.resize(h * w * 3);
diff --git a/tools/llava/clip.h b/tools/llava/clip.h
index 0a53bd8e..98d4e009 100644
--- a/tools/llava/clip.h
+++ b/tools/llava/clip.h
@@ -37,6 +37,7 @@ struct clip_image_f32_batch;
 struct clip_context_params {
     bool use_gpu;
     enum ggml_log_level verbosity;
+    int32_t max_image_size = 0;
 };
 
 // deprecated, use clip_init
@@ -75,6 +76,7 @@ CLIP_API int clip_n_output_tokens_y(const struct clip_ctx * ctx, struct clip_ima
 CLIP_API int clip_n_mmproj_embd(const struct clip_ctx * ctx);
 
 CLIP_API int clip_uhd_num_image_embeds_col(struct clip_ctx * ctx_clip);
+CLIP_API int clip_uhd_num_image_embeds_col2(struct clip_ctx * ctx_clip, struct clip_image_size * load_image_size);
 CLIP_API void clip_add_load_image_size(struct clip_ctx * ctx_clip, struct clip_image_size * load_image_size);
 CLIP_API struct clip_image_size * clip_get_load_image_size(struct clip_ctx * ctx_clip);
 
@@ -124,6 +126,8 @@ CLIP_API bool clip_is_glm(const struct clip_ctx * ctx);
 CLIP_API bool clip_is_qwen2vl(const struct clip_ctx * ctx);
 CLIP_API bool clip_is_llava(const struct clip_ctx * ctx);
 CLIP_API bool clip_is_gemma3(const struct clip_ctx * ctx);
+CLIP_API bool clip_is_smolvlm(const struct clip_ctx * ctx);
+CLIP_API bool clip_is_pixtral(const struct clip_ctx * ctx);
 
 CLIP_API bool clip_encode_float_image (struct clip_ctx * ctx, int n_threads, float * img, int h, int w, float * vec);
 
