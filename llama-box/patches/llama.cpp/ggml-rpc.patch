diff --git a/ggml/src/ggml-rpc/ggml-rpc.cpp b/ggml/src/ggml-rpc/ggml-rpc.cpp
index a0667b7d..18f507fc 100644
--- a/ggml/src/ggml-rpc/ggml-rpc.cpp
+++ b/ggml/src/ggml-rpc/ggml-rpc.cpp
@@ -4,6 +4,8 @@
 #include "ggml-cpp.h"
 
 #include <cinttypes>
+#include <cerrno>
+#include <cstring>
 #include <string>
 #include <vector>
 #include <memory>
@@ -17,6 +19,7 @@
 #  endif
 #  include <windows.h>
 #  include <winsock2.h>
+#  include <ws2tcpip.h>
 #else
 #  include <arpa/inet.h>
 #  include <sys/socket.h>
@@ -27,6 +30,7 @@
 #  include <unistd.h>
 #endif
 #include <cstring>
+#include <utility>
 #include <fstream>
 #include <filesystem>
 
@@ -93,6 +97,7 @@ enum rpc_cmd {
     RPC_CMD_INIT_TENSOR,
     RPC_CMD_GET_ALLOC_SIZE,
     RPC_CMD_HELLO,
+    RPC_CMD_SUPPORT_OP,
     RPC_CMD_COUNT,
 };
 
@@ -103,6 +108,7 @@ struct rpc_msg_hello_rsp {
     uint8_t major;
     uint8_t minor;
     uint8_t patch;
+    bool enabled_cache;
 };
 
 struct rpc_msg_get_alloc_size_req {
@@ -178,6 +184,10 @@ struct rpc_msg_get_device_memory_rsp {
     uint64_t free_mem;
     uint64_t total_mem;
 };
+
+struct rpc_msg_support_op_rsp {
+    uint8_t result;
+};
 #pragma pack(pop)
 
 // RPC data structures
@@ -201,6 +211,7 @@ struct ggml_backend_rpc_context {
 
 struct ggml_backend_rpc_buffer_context {
     std::shared_ptr<socket_t> sock;
+    bool enabled_cache;
     void * base_ptr;
     uint64_t remote_ptr;
 };
@@ -265,6 +276,7 @@ static std::shared_ptr<socket_t> socket_connect(const char * host, int port) {
     }
     memcpy(&addr.sin_addr.s_addr, server->h_addr, server->h_length);
     if (connect(sock_ptr->fd, (struct sockaddr *)&addr, sizeof(addr)) < 0) {
+        fprintf(stderr, "Failed to connect host '%s:%d': %s\n", host, port, strerror(errno));
         return nullptr;
     }
     return sock_ptr;
@@ -311,11 +323,39 @@ static std::shared_ptr<socket_t> create_server_socket(const char * host, int por
     return sock;
 }
 
+const static size_t MAX_CHUNK = 1 << 23; // 8MiB
+
 static bool send_data(sockfd_t sockfd, const void * data, size_t size) {
     size_t bytes_sent = 0;
     while (bytes_sent < size) {
-        ssize_t n = send(sockfd, (const char *)data + bytes_sent, size - bytes_sent, 0);
+        size_t bytes_chunk = MIN(size - bytes_sent, MAX_CHUNK);
+        ssize_t n = send(sockfd, (const char *)data + bytes_sent, bytes_chunk, 0);
         if (n < 0) {
+            int err = errno;
+            if (err == EINTR || err == EAGAIN || err == EWOULDBLOCK) {
+                GGML_LOG_WARN("[%s] interrupted: data range = [%p, %p), bytes_sent = %zu, bytes_target = %zu, errno = %d, errmsg = %s, retrying...\n", __func__, data, (char *)data + size, bytes_sent, size, MAX_CHUNK, err, strerror(err));
+                continue; // try again
+            }
+            if (err != 0) {
+                GGML_LOG_ERROR("[%s] failed to send data: data range = [%p, %p), bytes_sent = %zu, bytes_target = %zu,  errno = %d, errmsg = %s\n", __func__, data, (char *)data + size, bytes_sent, size, MAX_CHUNK, err, strerror(err));
+                int serr = 0;
+                socklen_t serr_len = sizeof(serr);
+                int ret = getsockopt(sockfd, SOL_SOCKET, SO_ERROR, (char *)&serr, &serr_len);
+                if (ret < 0) {
+                    err = errno;
+                    GGML_LOG_ERROR("[%s] failed to get peer socket error: errno = %d, errmsg = %s\n", __func__, err, strerror(err));
+                } else if (serr != 0) {
+                    GGML_LOG_ERROR("[%s] peer socket error: errno = %d, errmsg = %s\n", __func__, serr, strerror(serr));
+                } else {
+                    struct sockaddr_in sin{};
+                    socklen_t addr_len = sizeof(sin);
+                    ret                = getpeername(sockfd, (struct sockaddr *)&sin, &addr_len);
+                    if (ret < 0) {
+                        err = errno;
+                        GGML_LOG_ERROR("[%s] peer may have been disconnected: errno = %d, errmsg = %s\n", __func__, err, strerror(err));
+                    }
+                }
+            }
             return false;
         }
         bytes_sent += n;
@@ -326,8 +366,34 @@ static bool send_data(sockfd_t sockfd, const void * data, size_t size) {
 static bool recv_data(sockfd_t sockfd, void * data, size_t size) {
     size_t bytes_recv = 0;
     while (bytes_recv < size) {
-        ssize_t n = recv(sockfd, (char *)data + bytes_recv, size - bytes_recv, 0);
+        size_t bytes_chunk = MIN(size - bytes_recv, MAX_CHUNK);
+        ssize_t n = recv(sockfd, (char *)data + bytes_recv, bytes_chunk, 0);
         if (n <= 0) {
+            int err = errno;
+            if (err == EINTR || err == EAGAIN || err == EWOULDBLOCK) {
+                GGML_LOG_WARN("[%s] interrupted: data range = [%p, %p), bytes_recv = %zu, bytes_target = %zu, errno = %d, errmsg = %s, retrying...\n", __func__, data, (char *)data + size, bytes_recv, size, err, strerror(err));
+                continue; // try again
+            }
+            if (err != 0 && err != ESRCH) {
+                GGML_LOG_ERROR("[%s] failed to recv data: data range = [%p, %p), bytes_recv = %zu, bytes_target = %zu, errno = %d, errmsg = %s\n", __func__, data, (char *)data + size, bytes_recv, size, err, strerror(err));
+                int serr = 0;
+                socklen_t serr_len = sizeof(serr);
+                int ret = getsockopt(sockfd, SOL_SOCKET, SO_ERROR, (char *)&serr, &serr_len);
+                if (ret < 0) {
+                    err = errno;
+                    GGML_LOG_ERROR("[%s] failed to get peer socket error: errno = %d, errmsg = %s\n", __func__, err, strerror(err));
+                } else if (serr != 0) {
+                    GGML_LOG_ERROR("[%s] peer socket error: errno = %d, errmsg = %s\n", __func__, serr, strerror(serr));
+                } else {
+                    struct sockaddr_in sin{};
+                    socklen_t addr_len = sizeof(sin);
+                    ret                = getpeername(sockfd, (struct sockaddr *)&sin, &addr_len);
+                    if (ret < 0) {
+                        err = errno;
+                        GGML_LOG_ERROR("[%s] peer may have been disconnected: errno = %d, errmsg = %s\n", __func__, err, strerror(err));
+                    }
+                }
+            }
             return false;
         }
         bytes_recv += n;
@@ -337,25 +403,37 @@ static bool recv_data(sockfd_t sockfd, void * data, size_t size) {
 
 static bool send_msg(sockfd_t sockfd, const void * msg, size_t msg_size) {
     if (!send_data(sockfd, &msg_size, sizeof(msg_size))) {
+        GGML_LOG_ERROR("[%s] failed to send msg size\n", __func__);
         return false;
     }
-    return send_data(sockfd, msg, msg_size);
+    bool ret = send_data(sockfd, msg, msg_size);
+    if (!ret) {
+        GGML_LOG_ERROR("[%s] failed to send msg data\n", __func__);
+    }
+    return ret;
 }
 
 static bool recv_msg(sockfd_t sockfd, void * msg, size_t msg_size) {
     uint64_t size;
     if (!recv_data(sockfd, &size, sizeof(size))) {
+        GGML_LOG_ERROR("[%s] failed to recv msg size\n", __func__);
         return false;
     }
     if (size != msg_size) {
+        GGML_LOG_ERROR("[%s] failed: msg size mismatch, expected %zu, got %" PRIu64 "\n", __func__, msg_size, size);
         return false;
     }
-    return recv_data(sockfd, msg, msg_size);
+    bool ret = recv_data(sockfd, msg, msg_size);
+    if (!ret) {
+        GGML_LOG_ERROR("[%s] failed to recv msg data\n", __func__);
+    }
+    return ret;
 }
 
 static bool recv_msg(sockfd_t sockfd, std::vector<uint8_t> & input) {
     uint64_t size;
     if (!recv_data(sockfd, &size, sizeof(size))) {
+        GGML_LOG_ERROR("[%s] failed to recv msg size\n", __func__);
         return false;
     }
     try {
@@ -364,7 +442,11 @@ static bool recv_msg(sockfd_t sockfd, std::vector<uint8_t> & input) {
         fprintf(stderr, "Failed to allocate input buffer of size %" PRIu64 "\n", size);
         return false;
     }
-    return recv_data(sockfd, input.data(), size);
+    bool ret = recv_data(sockfd, input.data(), size);
+    if (!ret) {
+        GGML_LOG_ERROR("[%s] failed to recv msg data\n", __func__);
+    }
+    return ret;
 }
 
 static bool parse_endpoint(const std::string & endpoint, std::string & host, int & port) {
@@ -382,24 +464,30 @@ static bool parse_endpoint(const std::string & endpoint, std::string & host, int
 static bool send_rpc_cmd(const std::shared_ptr<socket_t> & sock, enum rpc_cmd cmd, const void * input, size_t input_size, void * output, size_t output_size) {
     uint8_t cmd_byte = cmd;
     if (!send_data(sock->fd, &cmd_byte, sizeof(cmd_byte))) {
+        GGML_LOG_ERROR("[%s] failed to send command, cmd = %d\n", __func__, cmd);
         return false;
     }
     if (!send_data(sock->fd, &input_size, sizeof(input_size))) {
+        GGML_LOG_ERROR("[%s] failed to send input, cmd = %d, size = %zu\n", __func__, cmd, input_size);
         return false;
     }
     if (!send_data(sock->fd, input, input_size)) {
+        GGML_LOG_ERROR("[%s] failed to send input data, cmd = %d, size = %zu\n", __func__, cmd, input_size);
         return false;
     }
     // TODO: currently the output_size is always known, do we need support for commands with variable output size?
     // even if we do, we can skip sending output_size from the server for commands with known output size
     uint64_t out_size;
     if (!recv_data(sock->fd, &out_size, sizeof(out_size))) {
+        GGML_LOG_ERROR("[%s] failed to recv output size, cmd = %d\n", __func__, cmd);
         return false;
     }
     if (out_size != output_size) {
+        GGML_LOG_ERROR("[%s] failed: output size mismatch, cmd = %d, expected %zu, got %llu\n", __func__, cmd, output_size, out_size);
         return false;
     }
     if (!recv_data(sock->fd, output, output_size)) {
+        GGML_LOG_ERROR("[%s] failed to recv output data, cmd = %d, size = %zu\n", __func__, cmd, output_size);
         return false;
     }
     return true;
@@ -407,30 +495,38 @@ static bool send_rpc_cmd(const std::shared_ptr<socket_t> & sock, enum rpc_cmd cm
 
 // RPC client-side implementation
 
-static bool check_server_version(const std::shared_ptr<socket_t> & sock) {
+static std::pair<bool, bool> check_server_version(const std::shared_ptr<socket_t> & sock) {
     rpc_msg_hello_rsp response;
     bool status = send_rpc_cmd(sock, RPC_CMD_HELLO, nullptr, 0, &response, sizeof(response));
-    GGML_ASSERT(status);
+    GGML_ASSERT(status && "failed to send hello command");
     if (response.major != RPC_PROTO_MAJOR_VERSION || response.minor > RPC_PROTO_MINOR_VERSION) {
         fprintf(stderr, "RPC server version mismatch: %d.%d.%d\n", response.major, response.minor, response.patch);
-        return false;
+        return {false, false};
     }
     if (response.minor != RPC_PROTO_MINOR_VERSION || response.patch != RPC_PROTO_PATCH_VERSION) {
         fprintf(stderr, "WARNING: RPC server version mismatch: %d.%d.%d\n", response.major, response.minor, response.patch);
     }
-    return true;
+    return {true, response.enabled_cache};
 }
 
-static std::shared_ptr<socket_t> get_socket(const std::string & endpoint) {
+struct socket_tw {
+    std::shared_ptr<socket_t> sock;
+    bool enabled_cache;
+
+    socket_tw(std::shared_ptr<socket_t> sock, bool enabled_cache) : sock(sock), enabled_cache(enabled_cache) {}
+};
+
+static std::unique_ptr<socket_tw> get_socket(const std::string & endpoint) {
     static std::mutex mutex;
     std::lock_guard<std::mutex> lock(mutex);
     static std::unordered_map<std::string, std::weak_ptr<socket_t>> sockets;
+    static std::unordered_map<std::string, bool> sockets_cache_enabled;
     static bool initialized = false;
 
     auto it = sockets.find(endpoint);
     if (it != sockets.end()) {
         if (auto sock = it->second.lock()) {
-            return sock;
+            return std::make_unique<socket_tw>(sock, sockets_cache_enabled[endpoint]);
         }
     }
     std::string host;
@@ -454,19 +550,21 @@ static std::shared_ptr<socket_t> get_socket(const std::string & endpoint) {
     if (sock == nullptr) {
         return nullptr;
     }
-    if (!check_server_version(sock)) {
+    std::pair<bool, bool> checked = check_server_version(sock);
+    if (!checked.first) {
         return nullptr;
     }
     GGML_PRINT_DEBUG("[%s] connected to %s, sockfd=%d\n", __func__, endpoint.c_str(), sock->fd);
     sockets[endpoint] = sock;
-    return sock;
+    sockets_cache_enabled[endpoint] = checked.second;
+    return std::make_unique<socket_tw>(sock, checked.second);
 }
 
 static void ggml_backend_rpc_buffer_free_buffer(ggml_backend_buffer_t buffer) {
     ggml_backend_rpc_buffer_context * ctx = (ggml_backend_rpc_buffer_context *)buffer->context;
     rpc_msg_free_buffer_req request = {ctx->remote_ptr};
     bool status = send_rpc_cmd(ctx->sock, RPC_CMD_FREE_BUFFER, &request, sizeof(request), nullptr, 0);
-    GGML_ASSERT(status);
+    GGML_UNUSED(status);
     delete ctx;
 }
 
@@ -478,7 +576,7 @@ static void * ggml_backend_rpc_buffer_get_base(ggml_backend_buffer_t buffer) {
     rpc_msg_buffer_get_base_req request = {ctx->remote_ptr};
     rpc_msg_buffer_get_base_rsp response;
     bool status = send_rpc_cmd(ctx->sock, RPC_CMD_BUFFER_GET_BASE, &request, sizeof(request), &response, sizeof(response));
-    GGML_ASSERT(status);
+    GGML_ASSERT(status && "failed to get buffer base");
     ctx->base_ptr = reinterpret_cast<void *>(response.base_ptr);
     return ctx->base_ptr;
 }
@@ -487,7 +585,7 @@ static rpc_tensor serialize_tensor(const ggml_tensor * tensor) {
     rpc_tensor result;
     result.id = reinterpret_cast<uint64_t>(tensor);
     result.type = tensor->type;
-    if (tensor->buffer) {
+    if (tensor->buffer && tensor->buffer->context) {
         ggml_backend_buffer_t buffer = tensor->buffer;
         ggml_backend_rpc_buffer_context * ctx = (ggml_backend_rpc_buffer_context *)buffer->context;
         result.buffer = ctx->remote_ptr;
@@ -525,7 +623,7 @@ static enum ggml_status ggml_backend_rpc_buffer_init_tensor(ggml_backend_buffer_
         request.tensor = serialize_tensor(tensor);
 
         bool status = send_rpc_cmd(ctx->sock, RPC_CMD_INIT_TENSOR, &request, sizeof(request), nullptr, 0);
-        GGML_ASSERT(status);
+        GGML_ASSERT(status && "failed to init tensor");
     }
     return GGML_STATUS_SUCCESS;
 }
@@ -533,7 +631,7 @@ static enum ggml_status ggml_backend_rpc_buffer_init_tensor(ggml_backend_buffer_
 static void ggml_backend_rpc_buffer_set_tensor(ggml_backend_buffer_t buffer, ggml_tensor * tensor, const void * data, size_t offset, size_t size) {
     ggml_backend_rpc_buffer_context * ctx = (ggml_backend_rpc_buffer_context *)buffer->context;
     rpc_tensor rpc_tensor = serialize_tensor(tensor);
-    if (size > HASH_THRESHOLD) {
+    if (ctx->enabled_cache && size > HASH_THRESHOLD) {
         // input serialization format: | rpc_tensor | offset (8 bytes) | hash (8 bytes)
         size_t input_size = sizeof(rpc_tensor) + sizeof(uint64_t) + sizeof(uint64_t);
         std::vector<uint8_t> input(input_size, 0);
@@ -543,7 +641,7 @@ static void ggml_backend_rpc_buffer_set_tensor(ggml_backend_buffer_t buffer, ggm
         memcpy(input.data() + sizeof(rpc_tensor) + sizeof(offset), &hash, sizeof(hash));
         rpc_msg_set_tensor_hash_rsp response;
         bool status = send_rpc_cmd(ctx->sock, RPC_CMD_SET_TENSOR_HASH, input.data(), input.size(), &response, sizeof(response));
-        GGML_ASSERT(status);
+        GGML_ASSERT(status && "failed to set tensor hash");
         if (response.result) {
             // the server has the same data, no need to send it
             return;
@@ -556,7 +654,7 @@ static void ggml_backend_rpc_buffer_set_tensor(ggml_backend_buffer_t buffer, ggm
     memcpy(input.data() + sizeof(rpc_tensor), &offset, sizeof(offset));
     memcpy(input.data() + sizeof(rpc_tensor) + sizeof(offset), data, size);
     bool status = send_rpc_cmd(ctx->sock, RPC_CMD_SET_TENSOR, input.data(), input.size(), nullptr, 0);
-    GGML_ASSERT(status);
+    GGML_ASSERT(status && "failed to set tensor");
 }
 
 static void ggml_backend_rpc_buffer_get_tensor(ggml_backend_buffer_t buffer, const ggml_tensor * tensor, void * data, size_t offset, size_t size) {
@@ -566,7 +664,7 @@ static void ggml_backend_rpc_buffer_get_tensor(ggml_backend_buffer_t buffer, con
     request.offset = offset;
     request.size = size;
     bool status = send_rpc_cmd(ctx->sock, RPC_CMD_GET_TENSOR, &request, sizeof(request), data, size);
-    GGML_ASSERT(status);
+    GGML_ASSERT(status && "failed to get tensor");
 }
 
 static bool ggml_backend_rpc_buffer_cpy_tensor(ggml_backend_buffer_t buffer, const ggml_tensor * src, ggml_tensor * dst) {
@@ -584,7 +682,7 @@ static bool ggml_backend_rpc_buffer_cpy_tensor(ggml_backend_buffer_t buffer, con
     request.dst = serialize_tensor(dst);
     rpc_msg_copy_tensor_rsp response;
     bool status = send_rpc_cmd(ctx->sock, RPC_CMD_COPY_TENSOR, &request, sizeof(request), &response, sizeof(response));
-    GGML_ASSERT(status);
+    GGML_ASSERT(status && "failed to copy tensor");
     return response.result;
 }
 
@@ -592,7 +690,7 @@ static void ggml_backend_rpc_buffer_clear(ggml_backend_buffer_t buffer, uint8_t
     ggml_backend_rpc_buffer_context * ctx = (ggml_backend_rpc_buffer_context *)buffer->context;
     rpc_msg_buffer_clear_req request = {ctx->remote_ptr, value};
     bool status = send_rpc_cmd(ctx->sock, RPC_CMD_BUFFER_CLEAR, &request, sizeof(request), nullptr, 0);
-    GGML_ASSERT(status);
+    GGML_ASSERT(status && "failed to clear buffer");
 }
 
 static ggml_backend_buffer_i ggml_backend_rpc_buffer_interface = {
@@ -617,12 +715,12 @@ static ggml_backend_buffer_t ggml_backend_rpc_buffer_type_alloc_buffer(ggml_back
     rpc_msg_alloc_buffer_req request = {size};
     rpc_msg_alloc_buffer_rsp response;
     auto sock = get_socket(buft_ctx->endpoint);
-    bool status = send_rpc_cmd(sock, RPC_CMD_ALLOC_BUFFER, &request, sizeof(request), &response, sizeof(response));
-    GGML_ASSERT(status);
+    bool status = send_rpc_cmd(sock->sock, RPC_CMD_ALLOC_BUFFER, &request, sizeof(request), &response, sizeof(response));
+    GGML_ASSERT(status && "failed to alloc buffer");
     if (response.remote_ptr != 0) {
         ggml_backend_buffer_t buffer = ggml_backend_buffer_init(buft,
             ggml_backend_rpc_buffer_interface,
-            new ggml_backend_rpc_buffer_context{sock, nullptr, response.remote_ptr},
+            new ggml_backend_rpc_buffer_context{sock->sock, sock->enabled_cache, nullptr, response.remote_ptr},
             response.remote_size);
         return buffer;
     } else {
@@ -633,7 +731,7 @@ static ggml_backend_buffer_t ggml_backend_rpc_buffer_type_alloc_buffer(ggml_back
 static size_t get_alignment(const std::shared_ptr<socket_t> & sock) {
     rpc_msg_get_alignment_rsp response;
     bool status = send_rpc_cmd(sock, RPC_CMD_GET_ALIGNMENT, nullptr, 0, &response, sizeof(response));
-    GGML_ASSERT(status);
+    GGML_ASSERT(status && "failed to get alignment");
     return response.alignment;
 }
 
@@ -645,7 +743,7 @@ static size_t ggml_backend_rpc_buffer_type_get_alignment(ggml_backend_buffer_typ
 static size_t get_max_size(const std::shared_ptr<socket_t> & sock) {
     rpc_msg_get_max_size_rsp response;
     bool status = send_rpc_cmd(sock, RPC_CMD_GET_MAX_SIZE, nullptr, 0, &response, sizeof(response));
-    GGML_ASSERT(status);
+    GGML_ASSERT(status && "failed to get max size");
     return response.max_size;
 }
 
@@ -665,8 +763,8 @@ static size_t ggml_backend_rpc_buffer_type_get_alloc_size(ggml_backend_buffer_ty
         request.tensor = serialize_tensor(tensor);
 
         rpc_msg_get_alloc_size_rsp response;
-        bool status = send_rpc_cmd(sock, RPC_CMD_GET_ALLOC_SIZE, &request, sizeof(request), &response, sizeof(response));
-        GGML_ASSERT(status);
+        bool status = send_rpc_cmd(sock->sock, RPC_CMD_GET_ALLOC_SIZE, &request, sizeof(request), &response, sizeof(response));
+        GGML_ASSERT(status && "failed to get alloc size");
 
         return response.alloc_size;
     } else {
@@ -743,8 +841,8 @@ static enum ggml_status ggml_backend_rpc_graph_compute(ggml_backend_t backend, g
     serialize_graph(cgraph, input);
     rpc_msg_graph_compute_rsp response;
     auto sock = get_socket(rpc_ctx->endpoint);
-    bool status = send_rpc_cmd(sock, RPC_CMD_GRAPH_COMPUTE, input.data(), input.size(), &response, sizeof(response));
-    GGML_ASSERT(status);
+    bool status = send_rpc_cmd(sock->sock, RPC_CMD_GRAPH_COMPUTE, input.data(), input.size(), &response, sizeof(response));
+    GGML_ASSERT(status && "failed to compute graph");
     return (enum ggml_status)response.result;
 }
 
@@ -778,8 +876,8 @@ ggml_backend_buffer_type_t ggml_backend_rpc_buffer_type(const char * endpoint) {
         fprintf(stderr, "Failed to connect to %s\n", endpoint);
         return nullptr;
     }
-    size_t alignment = get_alignment(sock);
-    size_t max_size = get_max_size(sock);
+    size_t alignment = get_alignment(sock->sock);
+    size_t max_size = get_max_size(sock->sock);
     ggml_backend_rpc_buffer_type_context * buft_ctx = new ggml_backend_rpc_buffer_type_context {
         /* .endpoint  = */ endpoint,
         /* .name      = */ "RPC[" + std::string(endpoint) + "]",
@@ -818,7 +916,7 @@ bool ggml_backend_is_rpc(ggml_backend_t backend) {
 static void get_device_memory(const std::shared_ptr<socket_t> & sock, size_t * free, size_t * total) {
     rpc_msg_get_device_memory_rsp response;
     bool status = send_rpc_cmd(sock, RPC_CMD_GET_DEVICE_MEMORY, nullptr, 0, &response, sizeof(response));
-    GGML_ASSERT(status);
+    GGML_ASSERT(status && "failed to get device memory");
     *free = response.free_mem;
     *total = response.total_mem;
 }
@@ -830,7 +928,32 @@ void ggml_backend_rpc_get_device_memory(const char * endpoint, size_t * free, si
         *total = 0;
         return;
     }
-    get_device_memory(sock, free, total);
+    get_device_memory(sock->sock, free, total);
+}
+
+static bool ggml_backend_rpc_support_op(const char * endpoint, const ggml_tensor * tensor) {
+    std::vector<uint8_t> input;
+    {
+        std::vector<rpc_tensor> tensors;
+        for (int i = 0; i < GGML_MAX_SRC; i++) {
+            if (tensor->src[i] == nullptr) {
+                break;
+            }
+            tensors.push_back(serialize_tensor(tensor->src[i]));
+        }
+        tensors.push_back(serialize_tensor(tensor));
+        // serialization format: | n_tensors (4 bytes) | tensors (n_tensors * sizeof(rpc_tensor)) |
+        uint32_t n_tensors = tensors.size();
+        int input_size = sizeof(uint32_t) + n_tensors * sizeof(rpc_tensor);
+        input.resize(input_size, 0);
+        memcpy(input.data(), &n_tensors, sizeof(n_tensors));
+        memcpy(input.data() + sizeof(n_tensors), tensors.data(), n_tensors * sizeof(rpc_tensor));
+    }
+    rpc_msg_support_op_rsp response;
+    auto sock = get_socket(endpoint);
+    bool status = send_rpc_cmd(sock->sock, RPC_CMD_SUPPORT_OP, input.data(), input.size(), &response, sizeof(response));
+    GGML_ASSERT(status && "failed to check op support");
+    return response.result;
 }
 
 // RPC server-side implementation
@@ -856,6 +979,7 @@ public:
     bool graph_compute(const std::vector<uint8_t> & input, rpc_msg_graph_compute_rsp & response);
     bool init_tensor(const rpc_msg_init_tensor_req & request);
     bool get_alloc_size(const rpc_msg_get_alloc_size_req & request, rpc_msg_get_alloc_size_rsp & response);
+    bool support_op(const std::vector<uint8_t> & input, rpc_msg_support_op_rsp & response);
 
 private:
     bool get_cached_file(uint64_t hash, std::vector<uint8_t> & data);
@@ -875,6 +999,7 @@ void rpc_server::hello(rpc_msg_hello_rsp & response) {
     response.major = RPC_PROTO_MAJOR_VERSION;
     response.minor = RPC_PROTO_MINOR_VERSION;
     response.patch = RPC_PROTO_PATCH_VERSION;
+    response.enabled_cache = cache_dir != nullptr;
     GGML_PRINT_DEBUG("[%s] version: %d.%d.%d\n", __func__, response.major, response.minor, response.patch);
 }
 
@@ -1224,6 +1349,43 @@ bool rpc_server::copy_tensor(const rpc_msg_copy_tensor_req & request, rpc_msg_co
     return true;
 }
 
+bool rpc_server::support_op(const std::vector<uint8_t> & input, rpc_msg_support_op_rsp & response) {
+    // serialization format: | n_tensors (4 bytes) | tensors (n_tensors * sizeof(rpc_tensor)) |
+    if (input.size() < sizeof(uint32_t)) {
+        GGML_LOG_ERROR("[%s] invalid input size\n", __func__);
+        return false;
+    }
+    uint32_t n_tensors;
+    memcpy(&n_tensors, input.data(), sizeof(n_tensors));
+    if (input.size() < sizeof(uint32_t) + n_tensors * sizeof(rpc_tensor)) {
+        GGML_LOG_ERROR("[%s] invalid input size\n", __func__);
+        return false;
+    }
+    const rpc_tensor * tensors = (const rpc_tensor *)(input.data() + sizeof(uint32_t));
+    GGML_PRINT_DEBUG("[%s] n_tensors: %u\n", __func__, n_tensors);
+
+    size_t buf_size = ggml_tensor_overhead()*n_tensors;
+    struct ggml_init_params params {
+        /*.mem_size   =*/ buf_size,
+        /*.mem_buffer =*/ NULL,
+        /*.no_alloc   =*/ true,
+    };
+    ggml_context_ptr ctx_ptr { ggml_init(params) };
+    GGML_ASSERT(ctx_ptr != nullptr);
+    ggml_context * ctx = ctx_ptr.get();
+    ggml_tensor * tensor = deserialize_tensor(ctx, &tensors[n_tensors-1]);
+    for (uint32_t i = 0; i < n_tensors-1; i++) {
+        ggml_tensor * src = deserialize_tensor(ctx, &tensors[i]);
+        tensor->src[i] = src;
+    }
+    response.result = true;
+    if (backend->device->iface.supports_op) {
+        response.result = backend->device->iface.supports_op(backend->device, tensor);
+    }
+
+    return true;
+}
+
 ggml_tensor * rpc_server::create_node(uint64_t id,
                                       struct ggml_context * ctx,
                                       const std::unordered_map<uint64_t, const rpc_tensor*> & tensor_ptrs,
@@ -1514,6 +1676,20 @@ static void rpc_serve_client(ggml_backend_t backend, const char * cache_dir,
                 }
                 break;
             }
+            case RPC_CMD_SUPPORT_OP: {
+                std::vector<uint8_t> input;
+                if (!recv_msg(sockfd, input)) {
+                    return;
+                }
+                rpc_msg_support_op_rsp response;
+                if (!server.support_op(input, response)) {
+                    return;
+                }
+                if (!send_msg(sockfd, &response, sizeof(response))) {
+                    return;
+                }
+                break;
+            }
             default: {
                 fprintf(stderr, "Unknown command: %d\n", cmd);
                 return;
@@ -1626,10 +1802,26 @@ static ggml_backend_buffer_type_t ggml_backend_rpc_device_get_buffer_type(ggml_b
 }
 
 static bool ggml_backend_rpc_device_supports_op(ggml_backend_dev_t dev, const struct ggml_tensor * op) {
+    static std::unordered_map<std::string, std::unordered_map<std::string, bool>> caches;
+    ggml_backend_rpc_device_context * ctx = (ggml_backend_rpc_device_context *)dev->context;
+
+    auto &cache = caches[ctx->endpoint];
+    std::string key = op->name;
+    key += std::to_string(op->type);
+    for (int i = 0; i < GGML_MAX_DIMS; i++) {
+        key += std::to_string(op->ne[i]);
+    }
+    key += std::to_string(op->op);
+
+    auto it = cache.find(key);
+    if (it != cache.end()) {
+        return it->second;
+    }
+    bool result = ggml_backend_rpc_support_op(ctx->endpoint.c_str(), op);
+    cache[key] = result;
+    return result;
+
     GGML_UNUSED(dev);
-    GGML_UNUSED(op);
-    //TODO: call the remote backend and cache the results
-    return true;
 }
 
 static bool ggml_backend_rpc_device_supports_buft(ggml_backend_dev_t dev, ggml_backend_buffer_type_t buft) {
