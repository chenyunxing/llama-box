diff --git a/ggml/src/ggml-backend-impl.h b/ggml/src/ggml-backend-impl.h
index c36c12d6..949748ce 100644
--- a/ggml/src/ggml-backend-impl.h
+++ b/ggml/src/ggml-backend-impl.h
@@ -207,6 +207,8 @@ extern "C" {
     };
 
     // Internal backend registry API
+    static int ngl = -1;
+    GGML_API void ggml_backend_register_metadata_set(int ngl_);
     GGML_API void ggml_backend_register(ggml_backend_reg_t reg);
 
     // Add backend dynamic loading support to the backend
diff --git a/ggml/src/ggml-backend-reg.cpp b/ggml/src/ggml-backend-reg.cpp
index f0cdac31..3fb3518f 100644
--- a/ggml/src/ggml-backend-reg.cpp
+++ b/ggml/src/ggml-backend-reg.cpp
@@ -166,25 +166,39 @@ struct ggml_backend_registry {
 
     ggml_backend_registry() {
 #ifdef GGML_USE_CUDA
-        register_backend(ggml_backend_cuda_reg());
+        if (ngl != 0) {
+            register_backend(ggml_backend_cuda_reg());
+        }
 #endif
 #ifdef GGML_USE_METAL
-        register_backend(ggml_backend_metal_reg());
+        if (ngl != 0) {
+            register_backend(ggml_backend_metal_reg());
+        }
 #endif
 #ifdef GGML_USE_SYCL
-        register_backend(ggml_backend_sycl_reg());
+        if (ngl != 0) {
+            register_backend(ggml_backend_sycl_reg());
+        }
 #endif
 #ifdef GGML_USE_VULKAN
-        register_backend(ggml_backend_vk_reg());
+        if (ngl != 0) {
+            register_backend(ggml_backend_vk_reg());
+        }
 #endif
 #ifdef GGML_USE_WEBGPU
-        register_backend(ggml_backend_webgpu_reg());
+        if (ngl != 0) {
+            register_backend(ggml_backend_webgpu_reg());
+        }
 #endif
 #ifdef GGML_USE_OPENCL
-        register_backend(ggml_backend_opencl_reg());
+        if (ngl != 0) {
+            register_backend(ggml_backend_opencl_reg());
+        }
 #endif
 #ifdef GGML_USE_CANN
-        register_backend(ggml_backend_cann_reg());
+        if (ngl != 0) {
+            register_backend(ggml_backend_cann_reg());
+        }
 #endif
 #ifdef GGML_USE_BLAS
         register_backend(ggml_backend_blas_reg());
@@ -307,6 +321,10 @@ static ggml_backend_registry & get_reg() {
 }
 
 // Internal API
+void ggml_backend_register_metadata_set(int ngl_) {
+    ngl = ngl_;
+}
+
 void ggml_backend_register(ggml_backend_reg_t reg) {
     get_reg().register_backend(reg);
 }
@@ -571,16 +589,18 @@ void ggml_backend_load_all_from_path(const char * dir_path) {
     bool silent = false;
 #endif
 
+    if (ngl != 0) {
+        ggml_backend_load_best("cann", silent, dir_path);
+        ggml_backend_load_best("cuda", silent, dir_path);
+        ggml_backend_load_best("hip", silent, dir_path);
+        ggml_backend_load_best("metal", silent, dir_path);
+        ggml_backend_load_best("sycl", silent, dir_path);
+        ggml_backend_load_best("vulkan", silent, dir_path);
+        ggml_backend_load_best("opencl", silent, dir_path);
+        ggml_backend_load_best("musa", silent, dir_path);
+    }
     ggml_backend_load_best("blas", silent, dir_path);
-    ggml_backend_load_best("cann", silent, dir_path);
-    ggml_backend_load_best("cuda", silent, dir_path);
-    ggml_backend_load_best("hip", silent, dir_path);
-    ggml_backend_load_best("metal", silent, dir_path);
     ggml_backend_load_best("rpc", silent, dir_path);
-    ggml_backend_load_best("sycl", silent, dir_path);
-    ggml_backend_load_best("vulkan", silent, dir_path);
-    ggml_backend_load_best("opencl", silent, dir_path);
-    ggml_backend_load_best("musa", silent, dir_path);
     ggml_backend_load_best("cpu", silent, dir_path);
     // check the environment variable GGML_BACKEND_PATH to load an out-of-tree backend
     const char * backend_path = std::getenv("GGML_BACKEND_PATH");
diff --git a/src/llama.cpp b/src/llama.cpp
index 34906cdb..db75b00c 100644
--- a/src/llama.cpp
+++ b/src/llama.cpp
@@ -197,7 +197,7 @@ static struct llama_model * llama_model_load_from_file_impl(
     }
 
     // if using single GPU mode, remove all except the main GPU
-    if (params.split_mode == LLAMA_SPLIT_MODE_NONE) {
+    if (model->devices.size() > 0 && params.split_mode == LLAMA_SPLIT_MODE_NONE) {
         if (params.main_gpu < 0) {
             model->devices.clear();
         } else {
