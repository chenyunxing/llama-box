diff --git a/ggml/include/ggml-metal.h b/ggml/include/ggml-metal.h
index a6106944..cfb8b0f3 100644
--- a/ggml/include/ggml-metal.h
+++ b/ggml/include/ggml-metal.h
@@ -61,6 +61,8 @@ GGML_BACKEND_API void ggml_backend_metal_capture_next_compute(ggml_backend_t bac
 
 GGML_BACKEND_API ggml_backend_reg_t ggml_backend_metal_reg(void);
 
+GGML_BACKEND_API void ggml_backend_metal_get_device_memory(ggml_backend_t backend, size_t * free_mem, size_t * total_mem);
+
 #ifdef __cplusplus
 }
 #endif
diff --git a/ggml/src/ggml-metal/ggml-metal.m b/ggml/src/ggml-metal/ggml-metal.m
index f2268260..ec11e55d 100644
--- a/ggml/src/ggml-metal/ggml-metal.m
+++ b/ggml/src/ggml-metal/ggml-metal.m
@@ -1471,11 +1471,6 @@ static void ggml_metal_encode_node(
             } break;
     }
 
-    if (!ggml_metal_supports_op(ctx_dev, dst)) {
-        GGML_LOG_ERROR("%s: error: unsupported op '%s'\n", __func__, ggml_op_desc(dst));
-        GGML_ABORT("unsupported op");
-    }
-
     const int64_t  ne00 = src0 ? src0->ne[0] : 0;
     const int64_t  ne01 = src0 ? src0->ne[1] : 0;
     const int64_t  ne02 = src0 ? src0->ne[2] : 0;
@@ -2375,7 +2370,21 @@ static void ggml_metal_encode_node(
 
                 // find the break-even point where the matrix-matrix kernel becomes more efficient compared
                 // to the matrix-vector kernel
-                const int ne11_mm_min = 4;
+                int ne11_mm_min = 4;
+                switch (src0t) {
+                    case GGML_TYPE_F16:  ne11_mm_min = 4;  break;
+                    case GGML_TYPE_Q8_0: ne11_mm_min = 7;  break;
+                    case GGML_TYPE_Q2_K: ne11_mm_min = 15; break;
+                    case GGML_TYPE_Q3_K: ne11_mm_min = 7;  break;
+                    case GGML_TYPE_Q4_0:
+                    case GGML_TYPE_Q4_1: ne11_mm_min = 15; break;
+                    case GGML_TYPE_Q4_K: ne11_mm_min = 11; break;
+                    case GGML_TYPE_Q5_0:                          // not tested yet
+                    case GGML_TYPE_Q5_1: ne11_mm_min = 13; break; // not tested yet
+                    case GGML_TYPE_Q5_K: ne11_mm_min = 7;  break;
+                    case GGML_TYPE_Q6_K: ne11_mm_min = 7;  break;
+                    default:             ne11_mm_min = 4;  break;
+                }
 
                 // first try to use small-batch mat-mv kernels
                 // these should be efficient for BS [2, ~8]
@@ -2384,20 +2393,8 @@ static void ggml_metal_encode_node(
                      (
                       (
                        src0t == GGML_TYPE_F16  || // TODO: helper function
-                       src0t == GGML_TYPE_Q4_0 ||
-                       src0t == GGML_TYPE_Q4_1 ||
-                       src0t == GGML_TYPE_Q5_0 ||
-                       src0t == GGML_TYPE_Q5_1 ||
-                       src0t == GGML_TYPE_Q8_0 ||
                        src0t == GGML_TYPE_IQ4_NL ||
-                       false) && (ne11 >= 2 && ne11 <= 8)
-                     ) ||
-                     (
-                      (
-                       src0t == GGML_TYPE_Q4_K ||
-                       src0t == GGML_TYPE_Q5_K ||
-                       src0t == GGML_TYPE_Q6_K ||
-                       false) && (ne11 >= 4 && ne11 <= 8)
+                       false) && (ne11 >= 2 && ne11 <= 5)
                      )
                     )
                    ) {
@@ -2409,7 +2406,7 @@ static void ggml_metal_encode_node(
                     //       my current hypothesis is that the work grid is not evenly divisible for different nsg
                     //       values and there can be some tail effects when nsg is high. need to confirm this
                     //
-                    const int nsg    = 2;                 // num simdgroups per threadgroup
+                    const int nsg    = ne11 < 3 ?  2 : 4; // num simdgroups per threadgroup
                     const int nxpsg  = ne11 < 3 ? 16 : 8; // num threads along row per simdgroup
                     const int nypsg  = 32/nxpsg;          // num threads along col per simdgroup (i.e. a simdgroup processes that many src0 rows at a time)
                     const int r0ptg  = nypsg*nsg;         // num src0 rows per threadgroup
@@ -3192,7 +3189,7 @@ static void ggml_metal_encode_node(
             } break;
         case GGML_OP_RMS_NORM:
             {
-                GGML_ASSERT(ne00 % 4 == 0);
+                // GGML_ASSERT(ne00 % 4 == 0);
                 GGML_ASSERT(ggml_is_contiguous_1(src0));
 
                 float eps;
@@ -5357,4 +5354,8 @@ ggml_backend_reg_t ggml_backend_metal_reg(void) {
     return &g_ggml_backend_metal_reg;
 }
 
+void ggml_backend_metal_get_device_memory(ggml_backend_t backend, size_t *free, size_t *total) {
+    ggml_backend_metal_device_get_memory(backend->device, free, total);
+}
+
 GGML_BACKEND_DL_IMPL(ggml_backend_metal_reg)
